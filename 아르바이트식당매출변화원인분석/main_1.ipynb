{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMnqkHSc62LQ"
      },
      "source": [
        "# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zxcdhh-s2KaB"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xilTZQpuZfop"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# matplotlibì— ë‚˜ëˆ”ê³ ë”• í°íŠ¸ ì ìš©\n",
        "plt.rc('font', family='NanumBarunGothic')\n",
        "plt.rcParams['axes.unicode_minus'] = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQnSXq_Ia4oH"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_rows', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhHLFpwL6w-i"
      },
      "source": [
        "# ë°ì´í„° ì „ì²˜ë¦¬"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nikARMMOoXMu"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/naver_reviews_2.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXhmqVyEof8o"
      },
      "outputs": [],
      "source": [
        "df_copy = df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dq96UkuyZVqe"
      },
      "outputs": [],
      "source": [
        "# ì¤‘ë³µ ì œê±° (ìœ ì €+ë‚ ì§œ+ë‚´ìš©ì´ ê°™ìœ¼ë©´ ì¤‘ë³µ)\n",
        "df_copy = df_copy.drop_duplicates(subset=[\"user_id\", \"date\", \"review_text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4xBonCMZW5j"
      },
      "outputs": [],
      "source": [
        "# ë°©ë¬¸íšŸìˆ˜ ìˆ«ìë§Œ ì¶”ì¶œ\n",
        "df_copy[\"visit_count\"] = df_copy[\"visit_count\"].str.extract(r\"(\\d+)\").astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfSeJx2DZYDE"
      },
      "outputs": [],
      "source": [
        "# ë‚ ì§œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
        "df_copy[\"date\"] = pd.to_datetime(df_copy[\"date\"], errors=\"coerce\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPR0gmzn4-2v"
      },
      "outputs": [],
      "source": [
        "# visit_tagsì— ë‹¤ë¥¸ ì¢…ë¥˜ì˜ í•­ëª©ë“¤ì´ í•œë²ˆì— ë“¤ì–´ê°€ìˆì–´ì„œ ìƒˆë¡œìš´ ì—´ì„ ë§Œë“¤ì–´ì„œ ì´ë¥¼ ë‚˜ëˆ ì¤Œ.\n",
        "# ì‰¼í‘œë¡œ ìµœëŒ€ 5ê°œ í•­ëª©ê¹Œì§€ ë¶„ë¦¬ (ë¶€ì¡±í•˜ë©´ NaNìœ¼ë¡œ ìë™ ì±„ì›Œì§)\n",
        "split_cols = df_copy['visit_tags'].str.split(',', n=4, expand=True)\n",
        "\n",
        "# ì•ë’¤ ê³µë°± ì œê±°\n",
        "split_cols = split_cols.apply(lambda col: col.str.strip())\n",
        "\n",
        "# ì—´ ì´ë¦„ ì§€ì •\n",
        "split_cols.columns = ['visit_when', 'reservation', 'wait', 'visit_type', 'visit_who']\n",
        "\n",
        "# ì›ë³¸ ë°ì´í„°í”„ë ˆì„ì— ë³‘í•©\n",
        "df_copy = pd.concat([df_copy, split_cols], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAQb2e9r6j_a"
      },
      "outputs": [],
      "source": [
        "df_copy = df_copy.drop(columns=['visit_tags'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQ9y1yyI_-_b"
      },
      "outputs": [],
      "source": [
        "#visit_tagë¥¼ ë‚˜ëˆ„ëŠ” ê³¼ì •ì—ì„œ ëª‡ëª‡ ì—´ë“¤ì´ ì˜ëª» ë“¤ì–´ê° => reversion í•˜ë‚˜ë§Œ ì—†ìœ¼ë‹ˆê¹Œ ê·¸ëƒ¥ ê°€ì¥ ë§ì€ ì˜ˆì•½ ì—†ì´ ì´ìš©ìœ¼ë¡œ ëŒ€ì²´\n",
        "#58í–‰ì˜ ê°’ì„ ëŒ€ì²´\n",
        "df_copy.at[58, 'reservation'] = 'ì˜ˆì•½ ì—†ì´ ì´ìš©'\n",
        "df_copy.at[58, 'wait'] = 'ë°”ë¡œ ì…ì¥'\n",
        "df_copy.at[58, 'visit_type'] = 'ë°ì´íŠ¸'\n",
        "df_copy.at[58, 'visit_who'] = 'ì—°ì¸ãƒ»ë°°ìš°ì'\n",
        "\n",
        "#125í–‰ì˜ ê°’ì„ ëŒ€ì²´\n",
        "df_copy.at[125, 'reservation'] = 'ì˜ˆì•½ ì—†ì´ ì´ìš©'\n",
        "df_copy.at[125, 'wait'] = 'ë°”ë¡œ ì…ì¥'\n",
        "df_copy.at[125, 'visit_type'] = 'ì¹œëª©'\n",
        "df_copy.at[125, 'visit_who'] = 'ì—°ì¸ãƒ»ë°°ìš°ì'\n",
        "\n",
        "#133í–‰ì˜ ê°’ì„ ëŒ€ì²´\n",
        "df_copy.at[133, 'reservation'] = 'ì˜ˆì•½ ì—†ì´ ì´ìš©'\n",
        "df_copy.at[133, 'wait'] = 'ë°”ë¡œ ì…ì¥'\n",
        "df_copy.at[133, 'visit_type'] = 'ì¼ìƒ'\n",
        "df_copy.at[133, 'visit_who'] = 'ì•„ì´'\n",
        "\n",
        "#148í–‰ì˜ ê°’ì„ ëŒ€ì²´\n",
        "df_copy.at[148, 'reservation'] = 'ì˜ˆì•½ ì—†ì´ ì´ìš©'\n",
        "df_copy.at[148, 'wait'] = 'ë°”ë¡œ ì…ì¥'\n",
        "df_copy.at[148, 'visit_type'] = 'ì¼ìƒ'\n",
        "df_copy.at[148, 'visit_who'] = 'ì•„ì´'\n",
        "\n",
        "#251í–‰ì˜ ê°’ì„ ëŒ€ì²´\n",
        "df_copy.at[251, 'reservation'] = 'ì˜ˆì•½ ì—†ì´ ì´ìš©'\n",
        "df_copy.at[251, 'wait'] = 'ë°”ë¡œ ì…ì¥'\n",
        "df_copy.at[251, 'visit_type'] = 'ë°ì´íŠ¸'\n",
        "df_copy.at[251, 'visit_who'] = 'ë¶€ëª¨ë‹˜'\n",
        "\n",
        "#288í–‰ì˜ ê°’ì„ ëŒ€ì²´\n",
        "df_copy.at[288, 'reservation'] = 'ì˜ˆì•½ ì—†ì´ ì´ìš©'\n",
        "df_copy.at[288, 'wait'] = 'ë°”ë¡œ ì…ì¥'\n",
        "df_copy.at[288, 'visit_type'] = 'ì¹œëª©'\n",
        "df_copy.at[288, 'visit_who'] = 'ì¹œêµ¬'\n",
        "\n",
        "\n",
        "#298í–‰ì˜ ê°’ì„ ëŒ€ì²´\n",
        "df_copy.at[298, 'reservation'] = 'ì˜ˆì•½ ì—†ì´ ì´ìš©'\n",
        "df_copy.at[298, 'wait'] = 'ë°”ë¡œ ì…ì¥'\n",
        "df_copy.at[298, 'visit_type'] = 'ì¼ìƒ'\n",
        "df_copy.at[298, 'visit_who'] = 'ì•„ì´'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybZlw3-AGqSG"
      },
      "outputs": [],
      "source": [
        "df_copy.at[11, 'visit_type'] = 'ì¼ìƒ'\n",
        "df_copy.at[11, 'visit_who'] = 'í˜¼ì'\n",
        "\n",
        "df_copy.at[85, 'visit_type'] = 'ê°€ì¡±ëª¨ì„'\n",
        "df_copy.at[85, 'visit_who'] = 'ë¶€ëª¨ë‹˜'\n",
        "\n",
        "df_copy.at[109, 'visit_type'] = 'íšŒì‹'\n",
        "df_copy.at[109, 'visit_who'] = 'ì§€ì¸ãƒ»ë™ë£Œ'\n",
        "\n",
        "df_copy.at[137, 'visit_type'] = 'ì¼ìƒ'\n",
        "df_copy.at[137, 'visit_who'] = 'í˜¼ì'\n",
        "\n",
        "df_copy.at[178, 'visit_type'] = 'ê°€ì¡±ëª¨ì„'\n",
        "df_copy.at[178, 'visit_who'] = 'ë¶€ëª¨ë‹˜'\n",
        "\n",
        "df_copy.at[373, 'visit_who'] = 'ì—°ì¸ãƒ»ë°°ìš°ì'\n",
        "\n",
        "df_copy.at[358, 'visit_who'] = 'ì§€ì¸ãƒ»ë™ë£Œ'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibezhrMuIdC6"
      },
      "outputs": [],
      "source": [
        "# ì°¾ê³ ì í•˜ëŠ” ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸\n",
        "target_values = [\n",
        "    'ê°€ì¡±ëª¨ì„',\n",
        "    'ì¼ìƒ',\n",
        "    'ê°€ì¡±ëª¨ì„,',\n",
        "    'ë‚˜ë“¤ì´,',\n",
        "    'ë‚˜ë“¤ì´, ì—¬í–‰, ì¼ìƒ,',\n",
        "    'ì¼ìƒ, ê¸°ë…ì¼, íšŒì‹, ê°€ì¡±ëª¨ì„,'\n",
        "]\n",
        "\n",
        "# í•´ë‹¹ ê°’ì´ í¬í•¨ëœ í–‰ í•„í„°ë§\n",
        "filtered_df = df_copy[df_copy['visit_who'].isin(target_values)]\n",
        "\n",
        "# ê²°ê³¼ ì¶œë ¥\n",
        "filtered_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFVUQbAZKvuV"
      },
      "outputs": [],
      "source": [
        "df_copy.loc[[2,19,107,174,211,264,311], 'visit_who'] = 'ì—°ì¸ãƒ»ë°°ìš°ì'\n",
        "df_copy.loc[[35,226,241], 'visit_who'] = 'ì—°ì¸'\n",
        "df_copy.loc[[134,203,213, 216], 'visit_who'] = 'ì¹œêµ¬'\n",
        "df_copy.loc[[318], 'visit_who'] = 'ì§€ì¸ãƒ»ë™ë£Œ'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZDf1l9sP9oa"
      },
      "outputs": [],
      "source": [
        "# ëŒ€ìƒ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸\n",
        "target_indices = [4, 6, 8, 13, 18, 20, 22, 28, 30, 34, 39, 40, 41, 46, 47, 48, 54, 55, 57, 59, 63, 64, 65, 67, 70, 72, 75, 81, 82, 86, 88, 89, 99, 103, 104, 106, 108, 112, 117, 129, 132, 135, 138, 143, 147, 149, 151, 152, 154, 156, 157, 159, 160, 161, 163, 165, 168, 169, 170, 179, 186, 187, 190, 196, 197, 202, 205, 206, 212, 215, 222, 225, 230, 231, 233, 234, 238, 239, 245, 246, 247, 249, 253, 257, 259, 260, 265, 269, 270, 273, 274, 277, 278, 279, 282, 284, 286, 287, 290, 292, 295, 299, 300, 301, 304, 306, 313, 321, 325, 326, 327, 328, 329, 330, 332, 340, 341, 348, 350, 352, 356, 357, 359, 360]\n",
        "\n",
        "# ì¡°ê±´ë³„ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬\n",
        "type_to_who = {\n",
        "    'ì¼ìƒ': 'ì—°ì¸ãƒ»ë°°ìš°ì',\n",
        "    'ë°ì´íŠ¸': 'ì—°ì¸',\n",
        "    'ì¹œëª©': 'ì¹œêµ¬',\n",
        "    'íšŒì‹': 'ì§€ì¸ãƒ»ë™ë£Œ',\n",
        "    'ë‚˜ë“¤ì´': 'ì—°ì¸ãƒ»ë°°ìš°ì',\n",
        "    'ê°€ì¡±ëª¨ì„': 'ë¶€ëª¨ë‹˜',\n",
        "    'ë¹„ì¦ˆë‹ˆìŠ¤': 'ì§€ì¸ãƒ»ë™ë£Œ'\n",
        "\n",
        "}\n",
        "\n",
        "# ì ìš©\n",
        "for idx in target_indices:\n",
        "    visit_type = df_copy.at[idx, 'visit_type']\n",
        "    if pd.notna(visit_type) and visit_type in type_to_who:\n",
        "        df_copy.at[idx, 'visit_who'] = type_to_who[visit_type]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMgt0BoSRjjR"
      },
      "outputs": [],
      "source": [
        "# ëŒ€ìƒ ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸\n",
        "target_indices = [7, 31,60, 126, 139, 195, 235, 266]\n",
        "\n",
        "# ì¡°ê±´ë³„ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬\n",
        "type_to_who = {\n",
        "    'ë°ì´íŠ¸': 'ì—°ì¸',\n",
        "    'ì¹œëª©': 'ì¹œêµ¬'\n",
        "}\n",
        "\n",
        "# ì ìš©\n",
        "for idx in target_indices:\n",
        "    visit_type = df_copy.at[idx, 'visit_type']\n",
        "    if pd.notna(visit_type) and visit_type in type_to_who:\n",
        "        df_copy.at[idx, 'visit_who'] = type_to_who[visit_type]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcjkimHWO_1Z"
      },
      "outputs": [],
      "source": [
        "# ì¡°ê±´: visit_typeì€ ì¡´ì¬í•˜ê³ , visit_whoëŠ” NaN ë˜ëŠ” ë¹ˆ ë¬¸ìì—´\n",
        "missing_who_idx = df_copy[\n",
        "    df_copy['visit_type'].notna() & ((df_copy['visit_who'].isna()) | (df_copy['visit_who'].str.strip() == ''))\n",
        "].index\n",
        "\n",
        "# ê²°ê³¼ ì¶œë ¥\n",
        "print(\"í•´ë‹¹ í–‰ ë²ˆí˜¸ë“¤:\", missing_who_idx.tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EX-v7VBATHhH"
      },
      "outputs": [],
      "source": [
        "df_copy.to_csv('df_after.csv', index=False, encoding='utf-8-sig')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ì—‘ì…€ ë‚´ì—ì„œ ë§¤ì¶œ ë°ì´í„°ì™€ df_after.csvë¥¼ í†µí•©í•˜ì—¬ df_final.csv ìƒì„±"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tElssX92TvU3"
      },
      "outputs": [],
      "source": [
        "df_final = pd.read_csv('/content/df_final.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZogIPh9-8hj"
      },
      "source": [
        "## ì‹œê°„ì— ë”°ë¥¸ ë§¤ì¶œ ì¶”ì´"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHBXF332_Cp0"
      },
      "outputs": [],
      "source": [
        "# ë‚ ì§œ í˜•ì‹ ë³€í™˜\n",
        "df = df_final.copy()\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "\n",
        "# ë‚ ì§œë³„ ë§¤ì¶œ í•©ê³„ ê³„ì‚°\n",
        "daily_sales = df.groupby('date')['sales'].sum().reset_index()\n",
        "\n",
        "# ì‹œê°í™”\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(daily_sales['date'], daily_sales['sales'], color='mediumblue', linewidth=2)\n",
        "plt.title(\"2024.01 ~ 2025.04 ë§¤ì¶œ ì¶”ì´\", fontsize=14)\n",
        "plt.xlabel(\"ë‚ ì§œ\")\n",
        "plt.ylabel(\"ë§¤ì¶œ (ì›)\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TI2pY2HZtd9y"
      },
      "source": [
        "## í‚¤ì›Œë“œ ë¶„ì„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ri19005sVWhG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ í•¨ìˆ˜ (í•œê¸€ë§Œ ë‚¨ê¸°ê¸°)\n",
        "def clean_text(text):\n",
        "    text = str(text)\n",
        "    text = re.sub(r'[^ê°€-í£\\s]', '', text)\n",
        "    return text\n",
        "\n",
        "df_final['cleaned_review'] = df_final['review_text'].apply(clean_text)\n",
        "\n",
        "# -----------------------------\n",
        "# (1) 'ì•„ì´', 'ê°€ì¡±' í‚¤ì›Œë“œ ë¶„ì„\n",
        "# -----------------------------\n",
        "baby_keywords = ['ì•„ì´']\n",
        "\n",
        "df_baby = df_final[df_final['cleaned_review'].str.contains('|'.join(baby_keywords), na=False)]\n",
        "overall_sales = df_final['sales'].mean()\n",
        "\n",
        "baby_sales = df_baby['sales'].mean()\n",
        "\n",
        "print(\"\\nğŸ“ [1] 'ì•„ì´' í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼\")\n",
        "print(f\"'ì•„ì´' í‚¤ì›Œë“œ ë¦¬ë·° í‰ê·  ë§¤ì¶œ: {baby_sales:,.0f}ì› (ì „ì²´ í‰ê·  ë§¤ì¶œ: {overall_sales:,.0f}ì›)\")\n",
        "\n",
        "# -----------------------------\n",
        "# (2) 'í˜¼ë°¥', 'ê°€ëŠ¥' í‚¤ì›Œë“œ ë¶„ì„\n",
        "# -----------------------------\n",
        "solo_keywords = ['í˜¼ë°¥']\n",
        "\n",
        "df_solo = df_final[df_final['cleaned_review'].str.contains('|'.join(solo_keywords), na=False)]\n",
        "\n",
        "solo_sales = df_solo['sales'].mean()\n",
        "\n",
        "print(\"\\nğŸ“ [2] 'í˜¼ë°¥' í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼\")\n",
        "print(f\"'í˜¼ë°¥' ê´€ë ¨ ë¦¬ë·° í‰ê·  ë§¤ì¶œ: {solo_sales:,.0f}ì› (ì „ì²´ í‰ê· : {overall_sales:,.0f}ì›)\")\n",
        "\n",
        "# -----------------------------\n",
        "# (3) 'ì°Œê°œ' vs 'ê³ ê¸°' í‚¤ì›Œë“œ ë¶„ì„ (ì‹œê°„ëŒ€ ë¹„êµ)\n",
        "# -----------------------------\n",
        "\n",
        "jjigae_keywords = ['ê¹€ì¹˜ì°Œê°œ']\n",
        "meat_keywords = ['ê³ ê¸°']\n",
        "\n",
        "df_jjigae = df_final[df_final['cleaned_review'].str.contains('|'.join(jjigae_keywords), na=False)]\n",
        "df_meat = df_final[df_final['cleaned_review'].str.contains('|'.join(meat_keywords), na=False)]\n",
        "\n",
        "jjigae_sales = df_jjigae['sales'].mean()\n",
        "meat_sales = df_meat['sales'].mean()\n",
        "\n",
        "print(\"\\nğŸ“ [3] 'ì°Œê°œ' vs 'ê³ ê¸°' í‚¤ì›Œë“œ ì‹œê°„ëŒ€ ë¶„ì„ ê²°ê³¼\")\n",
        "print(f\"'ì°Œê°œ' í‚¤ì›Œë“œ ë¦¬ë·° í‰ê·  ë§¤ì¶œ: {jjigae_sales:,.0f}ì›\")\n",
        "print(f\"'ê³ ê¸°' í‚¤ì›Œë“œ ë¦¬ë·° í‰ê·  ë§¤ì¶œ: {meat_sales:,.0f}ì›\")\n",
        "\n",
        "# -----------------------------\n",
        "# ì¶”ê°€ ì‹œê°í™” (ì„ íƒ)\n",
        "# -----------------------------\n",
        "# í‚¤ì›Œë“œë³„ ë§¤ì¶œ ë¹„êµ\n",
        "labels = ['ì „ì²´', 'ì•„ì´', 'í˜¼ë°¥', 'ê¹€ì¹˜ì°Œê°œ', 'ê³ ê¸°']\n",
        "sales_values = [overall_sales, baby_sales, solo_sales, jjigae_sales, meat_sales]\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.bar(labels, sales_values)\n",
        "plt.title('í‚¤ì›Œë“œë³„ í‰ê·  ë§¤ì¶œ ë¹„êµ')\n",
        "plt.ylabel('Average Sales (KRW)')\n",
        "plt.xlabel('Keyword Group')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZyI1HuwFy1S"
      },
      "source": [
        "## ë¦¬ë·° ìˆ˜ì™€ ë§¤ì¶œ ê°„ì˜ ìƒê´€ê´€ê³„ ë¶„ì„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTQbb-ciK9ga"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "\n",
        "# ë°ì´í„° ì¤€ë¹„\n",
        "# dfëŠ” ì´ë¯¸ ì¡´ì¬í•œë‹¤ê³  ê°€ì • (df['review_text'], df['sales'] ì»¬ëŸ¼ í¬í•¨)\n",
        "\n",
        "# 1. ë¦¬ë·° ìˆ˜ ì¡´ì¬ ì—¬ë¶€ ì»¬ëŸ¼ ìƒì„±\n",
        "df['has_review'] = df['review_text'].notnull().astype(int)\n",
        "\n",
        "# 2. ë‚ ì§œë³„ ë¦¬ë·° ìˆ˜ì™€ ë§¤ì¶œ í•©ê³„ ê³„ì‚°\n",
        "daily_summary = df.groupby('date').agg({\n",
        "    'has_review': 'sum',  # ë‚ ì§œë³„ ë¦¬ë·° ìˆ˜\n",
        "    'sales': 'sum'        # ë‚ ì§œë³„ ë§¤ì¶œ í•©ê³„\n",
        "}).rename(columns={'has_review': 'review_count'})\n",
        "\n",
        "# 3. í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ (ì„ í˜• ê´€ê³„)\n",
        "pearson_corr, pearson_p = pearsonr(daily_summary['review_count'], daily_summary['sales'])\n",
        "\n",
        "# 4. ìŠ¤í”¼ì–´ë§Œ ìƒê´€ê³„ìˆ˜ (ìˆœìœ„ ê¸°ë°˜ ë¹„ì„ í˜• ê´€ê³„)\n",
        "spearman_corr, spearman_p = spearmanr(daily_summary['review_count'], daily_summary['sales'])\n",
        "\n",
        "# 5. ê²°ê³¼ ì¶œë ¥\n",
        "print(f\"âœ… í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ (ì„ í˜•): {pearson_corr:.3f} (p-value: {pearson_p:.4f})\")\n",
        "print(f\"âœ… ìŠ¤í”¼ì–´ë§Œ ìƒê´€ê³„ìˆ˜ : {spearman_corr:.3f} (p-value: {spearman_p:.4f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ErfhVkgF2uv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# ë¦¬ë·° ìˆ˜ê°€ ì¡´ì¬í•˜ëŠ” ë‚ ì§œ ê³„ì‚°\n",
        "df['has_review'] = df['review_text'].notnull().astype(int)\n",
        "\n",
        "# ë‚ ì§œë³„ ë¦¬ë·° ìˆ˜ì™€ ë§¤ì¶œ í•©ê³„\n",
        "daily_summary = df.groupby('date').agg({\n",
        "    'has_review': 'sum',\n",
        "    'sales': 'sum'\n",
        "}).rename(columns={'has_review': 'review_count'})\n",
        "\n",
        "# ë§¤ì¶œ í‘œì¤€í™” (í‰ê·  0, í‘œì¤€í¸ì°¨ 1)\n",
        "scaler = StandardScaler()\n",
        "daily_summary['sales_scaled'] = scaler.fit_transform(daily_summary[['sales']])\n",
        "\n",
        "# ë¦¬ë·° ìˆ˜ê°€ 0, 1, 2, 3, 4ì¸ ê²½ìš°ë§Œ í•„í„°ë§\n",
        "filtered_summary = daily_summary[daily_summary['review_count'].isin([0, 1, 2, 3, 4])]\n",
        "\n",
        "# ì‹œê°í™”\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.scatterplot(\n",
        "    data=filtered_summary,\n",
        "    x='review_count',\n",
        "    y='sales_scaled',\n",
        "    color='mediumblue',  # ì  ìƒ‰ê¹” ì§€ì •\n",
        "    marker='x'       # x ëª¨ì–‘ ë§ˆì»¤ë¡œ ë³€ê²½\n",
        ")\n",
        "plt.title(\"ë¦¬ë·° ìˆ˜ (0~4ê°œ) vs ì¼ ë³„ ë§¤ì¶œ (í‘œì¤€í™”)\")\n",
        "plt.xlabel(\"ë¦¬ë·° ìˆ˜\")\n",
        "plt.ylabel(\"í‘œì¤€í™”ëœ ë§¤ì¶œ\")\n",
        "plt.grid(False)  # ê·¸ë¦¬ë“œ ì œê±°\n",
        "plt.xticks([0, 1, 2, 3, 4])  # Xì¶•ì„ 0~4ë¡œ ê³ ì •\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ddr9r36qPorB"
      },
      "outputs": [],
      "source": [
        "# visit_who ê·¸ë£¹ í†µí•© ë§¤í•‘\n",
        "visit_who_map = {\n",
        "    'ì§€ì¸ãƒ»ë™ë£Œ, ì•„ì´': 'ì•„ì´',\n",
        "    'ì¹œêµ¬, ì•„ì´': 'ì•„ì´',\n",
        "    'ì—°ì¸ãƒ»ë°°ìš°ì, ì•„ì´': 'ì•„ì´',\n",
        "    'ì—°ì¸': 'ì—°ì¸ãƒ»ë°°ìš°ì',\n",
        "    'ì—°ì¸ãƒ»ë°°ìš°ì, ì§€ì¸ãƒ»ë™ë£Œ': 'ì—°ì¸ãƒ»ë°°ìš°ì',\n",
        "    'ì—°ì¸ãƒ»ë°°ìš°ì, ë¶€ëª¨ë‹˜': 'ë¶€ëª¨ë‹˜',\n",
        "    'ì§€ì¸ãƒ»ë™ë£Œ': 'ì¹œêµ¬',\n",
        "    'ì¹œêµ¬, ì§€ì¸ãƒ»ë™ë£Œ': 'ì¹œêµ¬'\n",
        "}\n",
        "\n",
        "# ìƒˆ ë³€ìˆ˜ë¡œ ì €ì¥ (ê¸°ì¡´ê°’ ìœ ì§€ ì›í•  ê²½ìš°)\n",
        "df_final['visit_who_cleaned'] = df_final['visit_who'].replace(visit_who_map)\n",
        "\n",
        "# í•„ìš” ì—†ëŠ” ê·¸ë£¹ ì œê±°\n",
        "valid_groups = ['ì•„ì´', 'ì—°ì¸ãƒ»ë°°ìš°ì', 'ì¹œêµ¬', 'í˜¼ì', 'ë¶€ëª¨ë‹˜', 'ì¹œì²™ãƒ»í˜•ì œ']\n",
        "df_final = df_final[df_final['visit_who_cleaned'].isin(valid_groups)]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e26sCty_t0xr"
      },
      "source": [
        "## ë³€ìˆ˜ ë³„ ë§¤ì¶œì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ì˜í–¥ ë¶„ì„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkDkmqb3Imt7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import patsy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ê²°ì¸¡ ì œê±°\n",
        "df = df_final.dropna(subset=['sales', 'visit_who_cleaned'])\n",
        "\n",
        "# ë³€ìˆ˜ëª… êµì²´\n",
        "full_formula = 'sales ~ C(visit_when) + C(weekday) + C(reservation) + C(wait) + C(visit_type) + C(visit_who_cleaned)'\n",
        "y_full, X_full = patsy.dmatrices(full_formula, data=df, return_type='dataframe')\n",
        "model_full = sm.OLS(y_full, X_full).fit()\n",
        "r2_full = model_full.rsquared\n",
        "\n",
        "# ë¶„ì„ ëŒ€ìƒ ë³€ìˆ˜êµ°\n",
        "groups = ['visit_when', 'weekday', 'reservation', 'wait', 'visit_type', 'visit_who_cleaned']\n",
        "r2_drop = {}\n",
        "\n",
        "# ë³€ìˆ˜ ì œê±° í›„ RÂ² ë¹„êµ\n",
        "for group in groups:\n",
        "    reduced_formula = 'sales ~ ' + ' + '.join([f'C({g})' for g in groups if g != group])\n",
        "    y_reduced, X_reduced = patsy.dmatrices(reduced_formula, data=df, return_type='dataframe')\n",
        "    model_reduced = sm.OLS(y_reduced, X_reduced).fit()\n",
        "    r2_drop[group] = r2_full - model_reduced.rsquared\n",
        "\n",
        "# ê²°ê³¼ ì‹œê°í™”\n",
        "r2_df = pd.DataFrame({'ë³€ìˆ˜': list(r2_drop.keys()), 'ì„¤ëª…ë ¥ ê°ì†Œ(RÂ²)': list(r2_drop.values())})\n",
        "r2_df = r2_df.sort_values('ì„¤ëª…ë ¥ ê°ì†Œ(RÂ²)', ascending=True)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.barh(r2_df['ë³€ìˆ˜'], r2_df['ì„¤ëª…ë ¥ ê°ì†Œ(RÂ²)'], color='mediumblue')\n",
        "plt.title(\"ë³€ìˆ˜ ì œê±° ì‹œ ë§¤ì¶œ ì„¤ëª…ë ¥ ê°ì†Œ (RÂ² ê¸°ì¤€)\", fontsize=14)\n",
        "plt.xlabel(\"RÂ² ê°ì†ŒëŸ‰ (ë§¤ì¶œ ì„¤ëª…ë ¥ ì†ì‹¤)\", fontsize=12)\n",
        "\n",
        "for bar in bars:\n",
        "    plt.text(bar.get_width() + 0.001,\n",
        "             bar.get_y() + bar.get_height()/2,\n",
        "             f\"{bar.get_width():.4f}\",\n",
        "             va='center', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwS72FmWgdIm"
      },
      "source": [
        "## ê³ ê° ì„¸ë¶„í™”ë¥¼ ìœ„í•œ í´ëŸ¬ìŠ¤í„°ë§"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gT1kQggqaSle"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. ë°ì´í„° ì¤€ë¹„\n",
        "df['review_flag'] = df['review_text'].notnull().astype(int)\n",
        "daily_review = df.groupby('date')['review_flag'].sum().reset_index().rename(columns={'review_flag': 'review_count'})\n",
        "df = pd.merge(df, daily_review, on='date', how='left')\n",
        "\n",
        "df = df.dropna(subset=['sales', 'weekday','review_count'])\n",
        "cluster_df = df[['weekday', 'review_count', 'sales']].copy()\n",
        "\n",
        "# ì¸ì½”ë”©\n",
        "le_weekday = LabelEncoder()\n",
        "cluster_df['weekday_encoded'] = le_weekday.fit_transform(cluster_df['weekday'])\n",
        "\n",
        "# sales ìˆ«ìí˜• ë³€í™˜\n",
        "cluster_df['sales'] = cluster_df['sales'].astype(str).str.replace(',', '').astype(float)\n",
        "\n",
        "# í”¼ì²˜ êµ¬ì„± ë° ìŠ¤ì¼€ì¼ë§\n",
        "features = cluster_df[['weekday_encoded', 'review_count', 'sales']]\n",
        "scaler = StandardScaler()\n",
        "scaled_features = scaler.fit_transform(features)\n",
        "\n",
        "# GMM í´ëŸ¬ìŠ¤í„°ë§\n",
        "gmm = GaussianMixture(n_components=4, random_state=42)\n",
        "cluster_df['gmm_cluster'] = gmm.fit_predict(scaled_features)\n",
        "\n",
        "# PCA ì°¨ì› ì¶•ì†Œ\n",
        "pca = PCA(n_components=2)\n",
        "pca_result = pca.fit_transform(scaled_features)\n",
        "cluster_df['PCA1'] = pca_result[:, 0]\n",
        "cluster_df['PCA2'] = pca_result[:, 1]\n",
        "\n",
        "# í´ëŸ¬ìŠ¤í„°ë³„ í‰ê· ê°’ ê³„ì‚°\n",
        "summary = cluster_df.groupby('gmm_cluster').agg({\n",
        "    'review_count': 'mean',\n",
        "    'sales': 'mean',\n",
        "    'weekday': lambda x: x.mode()[0],  # ìµœë¹ˆê°’\n",
        "    'PCA1': 'mean',\n",
        "    'PCA2': 'mean'\n",
        "}).reset_index()\n",
        "\n",
        "# ì‹œê°í™”\n",
        "plt.figure(figsize=(10, 7))\n",
        "scatter = plt.scatter(\n",
        "    cluster_df['PCA1'], cluster_df['PCA2'],\n",
        "    c=cluster_df['gmm_cluster'],\n",
        "    cmap='Set2', alpha=0.7\n",
        ")\n",
        "plt.title('GMM í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ (PCA 2D)', fontsize=15)\n",
        "plt.xlabel('PCA1')\n",
        "plt.ylabel('PCA2')\n",
        "plt.grid(True)\n",
        "\n",
        "# í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ì— í‰ê·  ì •ë³´ ë¼ë²¨ í‘œì‹œ\n",
        "for _, row in summary.iterrows():\n",
        "    label = f\"Cluster {int(row['gmm_cluster'])}\\nğŸ“… {row['weekday']}\\nğŸ’¬ {row['review_count']:.2f}ê±´\\nğŸ’° {int(row['sales']):,}ì›\"\n",
        "    plt.text(row['PCA1'], row['PCA2'], label,\n",
        "             fontsize=9, fontweight='bold', ha='center',\n",
        "             bbox=dict(boxstyle='round,pad=0.3', fc='white', ec='gray', alpha=0.9))\n",
        "\n",
        "plt.colorbar(scatter, label='GMM Cluster')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gUoxWEu-WW7"
      },
      "outputs": [],
      "source": [
        "# í´ëŸ¬ìŠ¤í„°ë³„ í‰ê· ê°’ ê³„ì‚°\n",
        "summary = cluster_df.groupby('gmm_cluster').agg({\n",
        "    'review_count': 'mean',\n",
        "    'sales': 'mean',\n",
        "    'weekday': lambda x: x.mode()[0],  # ìµœë¹ˆê°’\n",
        "    'PCA1': 'mean',\n",
        "    'PCA2': 'mean'\n",
        "}).reset_index()\n",
        "\n",
        "# ì „ì²´ í‰ê·  ë§¤ì¶œ ê³„ì‚°\n",
        "overall_avg_sales = cluster_df['sales'].mean()\n",
        "\n",
        "# ê° í´ëŸ¬ìŠ¤í„°ì˜ ë§¤ì¶œì´ ì „ì²´ í‰ê·  ëŒ€ë¹„ ëª‡ í¼ì„¼íŠ¸ ì°¨ì´ ë‚˜ëŠ”ì§€ ê³„ì‚°\n",
        "summary['sales_diff_percent'] = ((summary['sales'] - overall_avg_sales) / overall_avg_sales) * 100\n",
        "\n",
        "# ì‹œê°í™”\n",
        "plt.figure(figsize=(10, 7))\n",
        "scatter = plt.scatter(\n",
        "    cluster_df['PCA1'], cluster_df['PCA2'],\n",
        "    c=cluster_df['gmm_cluster'],\n",
        "    cmap='Set2', alpha=0.7\n",
        ")\n",
        "plt.title('GMM í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼', fontsize=15)\n",
        "plt.xlabel('PCA1')\n",
        "plt.ylabel('PCA2')\n",
        "plt.grid(True)\n",
        "\n",
        "# í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ì— í‰ê·  ì •ë³´ ë¼ë²¨ í‘œì‹œ (ë§¤ì¶œ ëŒ€ë¹„ í¼ì„¼íŠ¸ ì°¨ì´ í‘œì‹œ)\n",
        "for _, row in summary.iterrows():\n",
        "    diff = row['sales_diff_percent']\n",
        "    sign = \"+\" if diff >= 0 else \"-\"\n",
        "    label = f\"Cluster {int(row['gmm_cluster'])}\\nğŸ“… {row['weekday']}\\nğŸ’¬ {row['review_count']:.2f}ê±´\\nğŸ“ˆ ì „ì²´ í‰ê·  ëŒ€ë¹„ {sign}{abs(diff):.1f}%\"\n",
        "    plt.text(row['PCA1'], row['PCA2'], label,\n",
        "             fontsize=9, fontweight='bold', ha='center',\n",
        "             bbox=dict(boxstyle='round,pad=0.3', fc='white', ec='gray', alpha=0.9))\n",
        "\n",
        "plt.colorbar(scatter, label='GMM Cluster')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKH8wsBE48kK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# í´ëŸ¬ìŠ¤í„° ë³„ ìƒ‰ìƒ ìˆ˜ë™ ì§€ì •\n",
        "# ìˆœì„œ: í´ëŸ¬ìŠ¤í„° 0, 1, 2, 3\n",
        "cluster_colors = {\n",
        "    0: 'mediumaquamarine',  # ì—°í•œ ë¶‰ì€ìƒ‰\n",
        "    1: 'lightskyblue',\n",
        "    2: 'gold',\n",
        "    3: 'lightcoral'\n",
        "}\n",
        "\n",
        "# ê° ë°ì´í„°ì— ìƒ‰ìƒì„ ë§¤í•‘\n",
        "cluster_df['color'] = cluster_df['gmm_cluster'].map(cluster_colors)\n",
        "\n",
        "# ì‹œê°í™”\n",
        "plt.figure(figsize=(10, 7))\n",
        "scatter = plt.scatter(\n",
        "    cluster_df['PCA1'], cluster_df['PCA2'],\n",
        "    c=cluster_df['color'],  # ì§ì ‘ ìƒ‰ìƒ ì§€ì •\n",
        "    alpha=0.7\n",
        ")\n",
        "plt.title('GMM í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼', fontsize=15)\n",
        "plt.xlabel('PCA1')\n",
        "plt.ylabel('PCA2')\n",
        "plt.grid(True)\n",
        "\n",
        "# í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ ë¼ë²¨ (ì´ì „ê³¼ ë™ì¼)\n",
        "for _, row in summary.iterrows():\n",
        "    diff = row['sales_diff_percent']\n",
        "    sign = \"+\" if diff >= 0 else \"-\"\n",
        "    label = f\"Cluster {int(row['gmm_cluster'])}\\nğŸ“… {row['weekday']}\\nğŸ’¬ {row['review_count']:.2f}ê±´\\nğŸ“ˆ ì „ì²´ í‰ê·  ëŒ€ë¹„ {sign}{abs(diff):.1f}%\"\n",
        "    plt.text(row['PCA1'], row['PCA2'], label,\n",
        "             fontsize=9, fontweight='bold', ha='center',\n",
        "             bbox=dict(boxstyle='round,pad=0.3', fc='white', ec='gray', alpha=0.9))\n",
        "\n",
        "plt.colorbar(scatter, label='GMM Cluster')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NNAOEt-njkK"
      },
      "outputs": [],
      "source": [
        "# í´ëŸ¬ìŠ¤í„°ë³„ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ í‰ê·  ê³„ì‚°\n",
        "cluster_summary = cluster_df.groupby('gmm_cluster')[['review_count', 'sales']].mean()\n",
        "\n",
        "# í´ëŸ¬ìŠ¤í„°ë³„ ëŒ€í‘œ ë²”ì£¼í˜• ë³€ìˆ˜ (ìµœë¹ˆê°’) ì¶”ì¶œ\n",
        "cluster_summary['weekday'] = cluster_df.groupby('gmm_cluster')['weekday'].agg(lambda x: x.mode()[0])\n",
        "\n",
        "# í´ëŸ¬ìŠ¤í„°ë³„ ì¸ì› ìˆ˜ ì¶”ê°€\n",
        "cluster_summary['count'] = cluster_df.groupby('gmm_cluster').size()\n",
        "\n",
        "# ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬\n",
        "cluster_summary = cluster_summary[['count', 'review_count', 'sales', 'weekday']]\n",
        "\n",
        "display(cluster_summary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRWI6_QC88_9"
      },
      "source": [
        "## XGBoostë¥¼ ì„±ëŠ¥ ì¸¡ì •\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZd6jhP-7vs8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ìš”ì¼ ì¸ì½”ë”©\n",
        "le = LabelEncoder()\n",
        "df['weekday_encoded'] = le.fit_transform(df['weekday'])\n",
        "\n",
        "# í”¼ì²˜ ë° íƒ€ê²Ÿ ì§€ì •\n",
        "X = df[['review_count', 'weekday_encoded']]\n",
        "y = df['sales']\n",
        "\n",
        "# í•™ìŠµìš© / í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° ë¶„í• \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# XGBoost íšŒê·€ ëª¨ë¸ í•™ìŠµ\n",
        "model = XGBRegressor(random_state=42, n_estimators=100, learning_rate=0.1)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# ì˜ˆì¸¡\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# ì„±ëŠ¥ í‰ê°€\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "# ê²°ê³¼ ì¶œë ¥\n",
        "print(\"ğŸ“Š XGBoost íšŒê·€ ëª¨ë¸ ì„±ëŠ¥\")\n",
        "print(f\"RÂ² (ê²°ì •ê³„ìˆ˜): {r2:.3f}\")\n",
        "print(f\"RMSE (í‰ê·  ì œê³±ê·¼ ì˜¤ì°¨): {int(rmse):,}ì›\")\n",
        "print(f\"MAE (í‰ê·  ì ˆëŒ“ê°’ ì˜¤ì°¨): {int(mae):,}ì›\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OEqQKCS0eoY"
      },
      "source": [
        "## ë¦¬ë·° ìˆ˜ ì¦ëŒ€ â†’ ë§¤ì¶œ ì¦ê°€ ì‹œë®¬ë ˆì´ì…˜ ì½”ë“œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjiEF6eS8iH8"
      },
      "outputs": [],
      "source": [
        "# í˜„ì¬ í‰ê·  ì…ë ¥ê°’ ì‚¬ìš©\n",
        "X_mean = X.mean()\n",
        "X_base = X_mean.copy()\n",
        "X_plus = X_mean.copy()\n",
        "\n",
        "# ë¦¬ë·° ìˆ˜ 1ê±´ ì¦ê°€\n",
        "X_plus['review_count'] += 1\n",
        "\n",
        "# ì…ë ¥ê°’ì„ DataFrameìœ¼ë¡œ ë³€í™˜\n",
        "X_base_df = pd.DataFrame([X_base])\n",
        "X_plus_df = pd.DataFrame([X_plus])\n",
        "\n",
        "# ì˜ˆì¸¡ê°’ ê³„ì‚°\n",
        "base_sales = model.predict(X_base_df)[0]\n",
        "plus_sales = model.predict(X_plus_df)[0]\n",
        "\n",
        "delta = plus_sales - base_sales\n",
        "\n",
        "print(f\"âœ… ë¦¬ë·° ìˆ˜ê°€ 1ê±´ ì¦ê°€í•˜ë©´ í•˜ë£¨ ë§¤ì¶œì€ ì•½ {int(delta):,}ì› ì¦ê°€í•  ê²ƒìœ¼ë¡œ ì˜ˆì¸¡ë©ë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8aUHkdQ0nRG"
      },
      "source": [
        "## ê³ ë§¤ì¶œ í´ëŸ¬ìŠ¤í„° ìœ ì… ì¦ê°€ ì‹œë®¬ë ˆì´ì…˜ ì˜ˆì‹œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U98Ay2iPM3Kb"
      },
      "outputs": [],
      "source": [
        "# ğŸ’¡ Cluster 3 í•˜ë£¨ í‰ê·  ë§¤ì¶œ ì‹œë®¬ë ˆì´ì…˜\n",
        "cluster_3 = cluster_df[cluster_df['gmm_cluster'] == 3].copy()\n",
        "cluster_3 = cluster_3.merge(df[['date', 'review_text']], left_index=True, right_index=True)\n",
        "cluster_3['date'] = pd.to_datetime(cluster_3['date'])\n",
        "\n",
        "cluster_3_unique = cluster_3.drop_duplicates(subset=['date', 'review_text'])\n",
        "cluster_3_daily = cluster_3.groupby(cluster_3['date'].dt.date)['sales'].mean().reset_index()\n",
        "daily_avg_sales_cluster3 = cluster_3_daily['sales'].mean()\n",
        "expected_increase = daily_avg_sales_cluster3 * 0.2\n",
        "\n",
        "print(f\"\\nğŸ’° Cluster 3 ê³ ê°êµ°ì´ í•˜ë£¨ ê¸°ì¤€ 20% ë” ìœ ì…ë˜ë©´, ë§¤ì¶œì€ ì•½ {int(expected_increase):,}ì› ì¦ê°€í•  ê²ƒìœ¼ë¡œ ì˜ˆì¸¡ë©ë‹ˆë‹¤.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MO20VtjlXBBV"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ê²°ê³¼ ê°’ ì…ë ¥ (ì˜ˆì‹œ ê¸°ë°˜, ì‹¤ì œ ê°’ì— ë§ê²Œ ìˆ˜ì • ê°€ëŠ¥)\n",
        "review_effect = 114426      # ë¦¬ë·° ìˆ˜ 1ê±´ ì¦ê°€ ì‹œ\n",
        "cluster3_effect = 285216    # Cluster 3 í•˜ë£¨ ìœ ì… 20% ì¦ê°€ ì‹œ\n",
        "\n",
        "# í•­ëª©ëª… ë° ê°’\n",
        "labels = ['ë¦¬ë·° ìˆ˜ 1ê±´ ì¦ê°€ ì‹œ', 'Cluster 3 ê³ ê° 20% ìœ ì… ì¦ê°€ ì‹œ']\n",
        "values = [review_effect, cluster3_effect]\n",
        "\n",
        "# ì‹œê°í™”\n",
        "plt.figure(figsize=(8, 5))\n",
        "bars = plt.bar(labels, values)\n",
        "plt.title('ì‹œë®¬ë ˆì´ì…˜ ê¸°ë°˜ ë§¤ì¶œ ì¦ê°€ ì˜ˆìƒ íš¨ê³¼', fontsize=14)\n",
        "plt.ylabel('ì˜ˆìƒ ë§¤ì¶œ ì¦ê°€ì•¡ (ì›)', fontsize=12)\n",
        "\n",
        "# ê°’ í‘œì‹œ\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width() / 2, height + 10000,\n",
        "             f\"{int(height):,}ì›\", ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
